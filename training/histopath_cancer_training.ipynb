{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781f279e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:10:44.891459Z",
     "iopub.status.busy": "2025-05-03T05:10:44.891271Z",
     "iopub.status.idle": "2025-05-03T05:14:24.905408Z",
     "shell.execute_reply": "2025-05-03T05:14:24.904488Z"
    },
    "papermill": {
     "duration": 220.021774,
     "end_time": "2025-05-03T05:14:24.907110",
     "exception": false,
     "start_time": "2025-05-03T05:10:44.885336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# installing libs\n",
    "!pip install -q tf-nightly[and-cuda]\n",
    "!pip install -q monai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73effb48",
   "metadata": {
    "papermill": {
     "duration": 0.003712,
     "end_time": "2025-05-03T05:14:24.915448",
     "exception": false,
     "start_time": "2025-05-03T05:14:24.911736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a94c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:24.924039Z",
     "iopub.status.busy": "2025-05-03T05:14:24.923790Z",
     "iopub.status.idle": "2025-05-03T05:14:24.927855Z",
     "shell.execute_reply": "2025-05-03T05:14:24.927180Z"
    },
    "papermill": {
     "duration": 0.009699,
     "end_time": "2025-05-03T05:14:24.928888",
     "exception": false,
     "start_time": "2025-05-03T05:14:24.919189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from monai.networks.nets import SegResNet\n",
    "\n",
    "# # Define the model parameters\n",
    "# spatial_dims = 2\n",
    "# in_channels = 1\n",
    "# out_channels = 2\n",
    "# blocks_down = [3, 4, 23, 3]\n",
    "# blocks_up = [3, 4, 3]\n",
    "# upsample_mode = \"deconv\"\n",
    "\n",
    "# blocks_down = [3, 4, 23, 3]  # Standard ResNet101 block configuration\n",
    "# blocks_up = [3, 6, 3]        # Enhanced decoder\n",
    "# init_filters = 32\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = SegResNet(\n",
    "#     spatial_dims=spatial_dims,\n",
    "#     in_channels=in_channels,\n",
    "#     out_channels=out_channels,\n",
    "#     blocks_down=blocks_down,\n",
    "#     blocks_up=blocks_up,\n",
    "#     upsample_mode=upsample_mode,\n",
    "#     init_filters = init_filters\n",
    "# )\n",
    "\n",
    "# # Calculate the number of parameters\n",
    "# num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# print(f\"The SegResNet model has {num_parameters/1000000} Million trainable parameters.\")\n",
    "\n",
    "# # Optional: Calculate model size in MB (assuming float32 parameters)\n",
    "# bytes_per_parameter = 4 # for float32\n",
    "# model_size_mb = (num_parameters * bytes_per_parameter) / (1024 * 1024)\n",
    "# print(f\"The estimated model size is {model_size_mb:.2f} MB (assuming float32).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699b6913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:24.937559Z",
     "iopub.status.busy": "2025-05-03T05:14:24.937356Z",
     "iopub.status.idle": "2025-05-03T05:14:24.950234Z",
     "shell.execute_reply": "2025-05-03T05:14:24.949483Z"
    },
    "papermill": {
     "duration": 0.018645,
     "end_time": "2025-05-03T05:14:24.951302",
     "exception": false,
     "start_time": "2025-05-03T05:14:24.932657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.networks.nets import SegResNet\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "class EmbeddingsDataset(Dataset):\n",
    "    \"\"\"Helper class to load and work with the stored embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_path, metadata_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Args:\n",
    "            embeddings_path: Path to the directory containing H5 embedding files\n",
    "            metadata_path: Path to the directory containing metadata files\n",
    "            transform: Optional transforms to apply to the data\n",
    "        \"\"\"\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.metadata_path = metadata_path\n",
    "        self.transform = transform\n",
    "        self.master_metadata = pd.read_parquet(os.path.join(metadata_path, \"master_metadata.parquet\"))\n",
    "        # Limit to data with labels\n",
    "        self.metadata = self.master_metadata.dropna(subset=['label'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get embedding and label for a specific index\"\"\"\n",
    "        row = self.metadata.iloc[idx]\n",
    "        batch_name = row['embedding_batch']\n",
    "        embedding_index = row['embedding_index']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Load the embedding\n",
    "        h5_path = os.path.join(self.embeddings_path, f\"{batch_name}.h5\")\n",
    "        with h5py.File(h5_path, 'r') as h5f:\n",
    "            embedding = h5f['embeddings'][embedding_index]\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        \n",
    "        # Reshape for CNN input - we expect embeddings of shape (384,)\n",
    "        # Reshape to (1, 384, 1, 1) for network input\n",
    "        embedding = embedding.view(1, 384, 1)\n",
    "        \n",
    "        # Convert label to tensor (0=negative, 1=positive)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "            \n",
    "        return embedding, label\n",
    "    \n",
    "    def get_embedding(self, file_id):\n",
    "        \"\"\"Get embedding for a specific file ID\"\"\"\n",
    "        # Find the file in metadata\n",
    "        file_info = self.master_metadata[self.master_metadata['file_id'] == file_id]\n",
    "        \n",
    "        if len(file_info) == 0:\n",
    "            raise ValueError(f\"File ID {file_id} not found in metadata\")\n",
    "        \n",
    "        # Get the batch and index\n",
    "        batch_name = file_info['embedding_batch'].iloc[0]\n",
    "        embedding_index = file_info['embedding_index'].iloc[0]\n",
    "        \n",
    "        # Load the embedding\n",
    "        h5_path = os.path.join(self.embeddings_path, f\"{batch_name}.h5\")\n",
    "        with h5py.File(h5_path, 'r') as h5f:\n",
    "            embedding = h5f['embeddings'][embedding_index]\n",
    "            \n",
    "        return embedding, file_info['label'].iloc[0] if 'label' in file_info.columns else None\n",
    "\n",
    "class SelfSupervisedHead(nn.Module):\n",
    "    \"\"\"Self-supervised learning head for cancer classification\n",
    "    \n",
    "    Since no coordinates or bounding boxes are available, this head focuses on\n",
    "    learning from the entire embedding through self-supervision.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_classes=2):\n",
    "        super(SelfSupervisedHead, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Self-supervised projector (MLP)\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply projector for self-supervised learning\n",
    "        features = self.projector(x)\n",
    "        \n",
    "        # Classification output\n",
    "        output = self.fc(features)\n",
    "        return output, features\n",
    "\n",
    "class SelfSupervisedCancerModel(nn.Module):\n",
    "    \"\"\"SegResNet with self-supervised learning head for cancer classification\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SelfSupervisedCancerModel, self).__init__()\n",
    "        # Initialize SegResNet as backbone\n",
    "        # Modified to work with 1-channel input and small input size\n",
    "        self.backbone = SegResNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=2,  # This is the number of output channels\n",
    "            blocks_down=[3, 4, 23, 3],\n",
    "            blocks_up=[3, 6, 3],\n",
    "            upsample_mode=\"deconv\",\n",
    "            init_filters=32,\n",
    "        )\n",
    "        \n",
    "        # We know from the structure that the final conv layer outputs 2 channels\n",
    "        # Look at the print of self.backbone.conv_final showing Conv2d(8, 2, ...)\n",
    "        backbone_out_channels = 2\n",
    "        \n",
    "        # Replace classifier with our self-supervised head\n",
    "        self.ssl_head = SelfSupervisedHead(backbone_out_channels, num_classes)\n",
    "        \n",
    "        # Remove original classifier if needed\n",
    "        if hasattr(self.backbone, 'class_layers'):\n",
    "            self.backbone.class_layers = nn.Identity()\n",
    "        \n",
    "    def forward(self, x, return_features=False):\n",
    "        # Run through backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Apply self-supervised head\n",
    "        output, proj_features = self.ssl_head(features)\n",
    "        \n",
    "        if return_features:\n",
    "            return output, proj_features\n",
    "        return output\n",
    "\n",
    "# NTXent Loss for contrastive learning\n",
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Normalized Temperature-scaled Cross Entropy Loss for contrastive learning\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, features, labels):\n",
    "        # Normalize features\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        \n",
    "        # Create masks for positive and negative pairs\n",
    "        batch_size = features.shape[0]\n",
    "        mask = torch.zeros_like(similarity_matrix)\n",
    "        \n",
    "        # For each anchor, samples with same label are positive pairs\n",
    "        for i in range(batch_size):\n",
    "            for j in range(batch_size):\n",
    "                if i != j and labels[i] == labels[j]:\n",
    "                    mask[i, j] = 1.0\n",
    "        \n",
    "        # Remove self-similarity from the matrix\n",
    "        mask_self = torch.eye(batch_size, device=features.device)\n",
    "        mask_not_self = 1 - mask_self\n",
    "        similarity_matrix = similarity_matrix * mask_not_self\n",
    "        \n",
    "        # Create labels for contrastive loss\n",
    "        # For each row, indices with same label are positive pairs\n",
    "        pos_mask = mask.bool()\n",
    "        if pos_mask.sum() == 0:  # If no positive pairs, return 0\n",
    "            return torch.tensor(0.0, device=features.device)\n",
    "            \n",
    "        # Create labels for each anchor: the class of positive samples\n",
    "        contrastive_labels = torch.zeros(batch_size, device=features.device).long()\n",
    "        for i in range(batch_size):\n",
    "            pos_indices = pos_mask[i].nonzero(as_tuple=True)[0]\n",
    "            if len(pos_indices) > 0:\n",
    "                contrastive_labels[i] = pos_indices[0]\n",
    "                \n",
    "        # Calculate loss\n",
    "        loss = self.criterion(similarity_matrix, contrastive_labels)\n",
    "        return loss\n",
    "\n",
    "def create_data_loaders(embeddings_path, metadata_path, batch_size=32, test_size=0.2, random_state=42):\n",
    "    \"\"\"Create PyTorch DataLoaders for training and validation\"\"\"\n",
    "    # Create full dataset\n",
    "    full_dataset = EmbeddingsDataset(embeddings_path, metadata_path)\n",
    "    \n",
    "    # Split indices for train/val\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(full_dataset)),\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=[full_dataset.metadata['label'].iloc[i] for i in range(len(full_dataset))]\n",
    "    )\n",
    "    \n",
    "    # Create subset datasets\n",
    "    from torch.utils.data import Subset\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_model_with_logging(model, train_loader, val_loader, checkpoint_path:str,\n",
    "                             device, writer, num_epochs=10, learning_rate=0.001,\n",
    "                             temperature=0.07):\n",
    "    \"\"\"Train the cancer detection model with self-supervised learning and TensorBoard logging\"\"\"\n",
    "    # Define loss functions and optimizer\n",
    "    classification_criterion = nn.CrossEntropyLoss()\n",
    "    contrastive_criterion = NTXentLoss(temperature)  # Contrastive loss for self-supervision\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Improved learning rate scheduler - CosineAnnealingWarmRestarts\n",
    "    # This provides cyclical learning rates with warm restarts\n",
    "    # Good for avoiding local minima and finding better global minima\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=5,           # Restart every 5 epochs\n",
    "        T_mult=1,        # Keep the same cycle length\n",
    "        eta_min=1e-5     # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Only load scheduler if it's compatible with our current scheduler\n",
    "        try:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        except:\n",
    "            print(\"Warning: Couldn't load scheduler state from checkpoint (may be different type)\")\n",
    "            # Manually advance scheduler to match the epoch\n",
    "            for _ in range(checkpoint['epoch']):\n",
    "                scheduler.step()\n",
    "                \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        if 'best_val_loss' in checkpoint:\n",
    "            best_val_loss = checkpoint['best_val_loss']\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_auc = 0.0\n",
    "    best_model_weights = None\n",
    "    \n",
    "    # Use trange for epoch progress\n",
    "    epoch_iterator = trange(num_epochs, desc=\"Epochs\")\n",
    "    for epoch in epoch_iterator:\n",
    "        print(\"epoc: \", epoch)\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_class_loss = 0.0\n",
    "        train_ssl_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Use tqdm for batch progress in training\n",
    "        batch_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch_idx, (embeddings, labels) in enumerate(batch_iterator):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with features\n",
    "            outputs, features = model(embeddings, return_features=True)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = classification_criterion(outputs, labels)\n",
    "            \n",
    "            # Self-supervised contrastive loss\n",
    "            # Group features by class for positive pairs\n",
    "            pos_indices = (labels == 1).nonzero(as_tuple=True)[0]\n",
    "            neg_indices = (labels == 0).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # Only compute contrastive loss if we have samples from both classes\n",
    "            if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                pos_features = features[pos_indices]\n",
    "                neg_features = features[neg_indices]\n",
    "                \n",
    "                # Create positive and negative pairs for contrastive learning\n",
    "                all_features = torch.cat([pos_features, neg_features], dim=0)\n",
    "                all_labels = torch.cat([\n",
    "                    torch.ones(len(pos_indices), device=device),\n",
    "                    torch.zeros(len(neg_indices), device=device)\n",
    "                ])\n",
    "                \n",
    "                # Compute contrastive loss\n",
    "                ssl_loss = contrastive_criterion(all_features, all_labels)\n",
    "                \n",
    "                # Total loss (weighted combination)\n",
    "                loss = class_loss + 0.5 * ssl_loss\n",
    "                train_ssl_loss += ssl_loss.item() * embeddings.size(0)\n",
    "            else:\n",
    "                # If we don't have samples from both classes, just use classification loss\n",
    "                loss = class_loss\n",
    "                ssl_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * embeddings.size(0)\n",
    "            train_class_loss += class_loss.item() * embeddings.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            # Log batch-level metrics (every 10 batches)\n",
    "            if batch_idx % 10 == 0:\n",
    "                global_step = epoch * len(train_loader) + batch_idx\n",
    "                writer.add_scalar('Batch/Loss/train', loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/ClassLoss/train', class_loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/SSLLoss/train', ssl_loss.item(), global_step)\n",
    "                \n",
    "                # Add histograms of model parameters\n",
    "                if batch_idx % 50 == 0:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            writer.add_histogram(f'Parameters/{name}', param.data, global_step)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_class_loss = train_class_loss / len(train_loader.dataset)\n",
    "        train_ssl_loss = train_ssl_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        \n",
    "        # Use tqdm for batch progress in validation\n",
    "        val_iterator = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_iterator:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(embeddings)\n",
    "                loss = classification_criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * embeddings.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Store for metrics calculation\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                all_probs.extend(probs)\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_iterator.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Calculate AUC and other metrics\n",
    "        from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, f1_score, confusion_matrix\n",
    "        val_auc = roc_auc_score(all_labels, all_probs)\n",
    "        val_ap = average_precision_score(all_labels, all_probs)\n",
    "        val_f1 = f1_score(all_labels, all_preds)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            torch.save(best_model_weights, f\"{LOG_DIR}/best_model_epoch_{epoch}.pth\")\n",
    "            writer.add_text('Training', f'New best model saved at epoch {epoch} with AUC {best_val_auc:.4f}', epoch)\n",
    "        \n",
    "        # Update epoch progress bar with metrics\n",
    "        epoch_iterator.set_postfix({\n",
    "            \"train_loss\": f\"{train_loss:.4f}\", \n",
    "            \"train_acc\": f\"{train_acc:.4f}\",\n",
    "            \"val_loss\": f\"{val_loss:.4f}\", \n",
    "            \"val_acc\": f\"{val_acc:.4f}\", \n",
    "            \"val_auc\": f\"{val_auc:.4f}\"\n",
    "        })\n",
    "        \n",
    "        # Log epoch-level metrics to TensorBoard\n",
    "        writer.add_scalar('Epoch/Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Epoch/ClassLoss/train', train_class_loss, epoch)\n",
    "        writer.add_scalar('Epoch/SSLLoss/train', train_ssl_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Epoch/Accuracy/val', val_acc, epoch)\n",
    "        writer.add_scalar('Epoch/AUC/val', val_auc, epoch)\n",
    "        writer.add_scalar('Epoch/AP/val', val_ap, epoch)\n",
    "        writer.add_scalar('Epoch/F1/val', val_f1, epoch)\n",
    "        writer.add_scalar('Epoch/Sensitivity/val', sensitivity, epoch)\n",
    "        writer.add_scalar('Epoch/Specificity/val', specificity, epoch)\n",
    "        writer.add_scalar('Epoch/LearningRate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        # Log PR curve (once every few epochs)\n",
    "        if epoch % 2 == 0:\n",
    "            precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "            # Create figure\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig = plt.figure()\n",
    "            plt.plot(recall, precision, marker='.', label=f'AP={val_ap:.3f}')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title(f'PR Curve - Epoch {epoch}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            # Add to tensorboard\n",
    "            writer.add_figure(f'PR_Curve/epoch_{epoch}', fig, epoch)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Add confusion matrix as figure\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            plt.imshow([[tn, fp], [fn, tp]], cmap='Blues', interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            thresh = (tn + fp + fn + tp) / 2\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    text = plt.text(j, i, [[tn, fp], [fn, tp]][i][j],\n",
    "                                    ha=\"center\", va=\"center\", color=\"white\" if [[tn, fp], [fn, tp]][i][j] > thresh else \"black\")\n",
    "            plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "            plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "            writer.add_figure(f'Confusion_Matrix/epoch_{epoch}', fig, epoch)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Log model graph with sample input\n",
    "    try:\n",
    "        sample_input = torch.rand(1, 1, 384, 1).to(device)\n",
    "        writer.add_graph(model, sample_input)\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't add model graph to TensorBoard: {e}\")\n",
    "        \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c2aa27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:24.960118Z",
     "iopub.status.busy": "2025-05-03T05:14:24.959899Z",
     "iopub.status.idle": "2025-05-03T05:14:50.683569Z",
     "shell.execute_reply": "2025-05-03T05:14:50.682899Z"
    },
    "papermill": {
     "duration": 25.730004,
     "end_time": "2025-05-03T05:14:50.685120",
     "exception": false,
     "start_time": "2025-05-03T05:14:24.955116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.networks.nets import SegResNet\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "class EmbeddingsDataset(Dataset):\n",
    "    \"\"\"Helper class to load and work with the stored embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_path, metadata_path, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Args:\n",
    "            embeddings_path: Path to the directory containing H5 embedding files\n",
    "            metadata_path: Path to the directory containing metadata files\n",
    "            transform: Optional transforms to apply to the data\n",
    "        \"\"\"\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.metadata_path = metadata_path\n",
    "        self.transform = transform\n",
    "        self.master_metadata = pd.read_parquet(os.path.join(metadata_path, \"master_metadata.parquet\"))\n",
    "        # Limit to data with labels\n",
    "        self.metadata = self.master_metadata.dropna(subset=['label'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get embedding and label for a specific index\"\"\"\n",
    "        row = self.metadata.iloc[idx]\n",
    "        batch_name = row['embedding_batch']\n",
    "        embedding_index = row['embedding_index']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Load the embedding\n",
    "        h5_path = os.path.join(self.embeddings_path, f\"{batch_name}.h5\")\n",
    "        with h5py.File(h5_path, 'r') as h5f:\n",
    "            embedding = h5f['embeddings'][embedding_index]\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        \n",
    "        # Reshape for CNN input - we expect embeddings of shape (384,)\n",
    "        # Reshape to (1, 384, 1, 1) for network input\n",
    "        embedding = embedding.view(1, 384, 1)\n",
    "        \n",
    "        # Convert label to tensor (0=negative, 1=positive)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            embedding = self.transform(embedding)\n",
    "            \n",
    "        return embedding, label\n",
    "    \n",
    "    def get_embedding(self, file_id):\n",
    "        \"\"\"Get embedding for a specific file ID\"\"\"\n",
    "        # Find the file in metadata\n",
    "        file_info = self.master_metadata[self.master_metadata['file_id'] == file_id]\n",
    "        \n",
    "        if len(file_info) == 0:\n",
    "            raise ValueError(f\"File ID {file_id} not found in metadata\")\n",
    "        \n",
    "        # Get the batch and index\n",
    "        batch_name = file_info['embedding_batch'].iloc[0]\n",
    "        embedding_index = file_info['embedding_index'].iloc[0]\n",
    "        \n",
    "        # Load the embedding\n",
    "        h5_path = os.path.join(self.embeddings_path, f\"{batch_name}.h5\")\n",
    "        with h5py.File(h5_path, 'r') as h5f:\n",
    "            embedding = h5f['embeddings'][embedding_index]\n",
    "            \n",
    "        return embedding, file_info['label'].iloc[0] if 'label' in file_info.columns else None\n",
    "\n",
    "class SelfSupervisedHead(nn.Module):\n",
    "    \"\"\"Self-supervised learning head for cancer classification\n",
    "    \n",
    "    Since no coordinates or bounding boxes are available, this head focuses on\n",
    "    learning from the entire embedding through self-supervision.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, num_classes=2):\n",
    "        super(SelfSupervisedHead, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Self-supervised projector (MLP)\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "        # Classification layer\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply projector for self-supervised learning\n",
    "        features = self.projector(x)\n",
    "        \n",
    "        # Classification output\n",
    "        output = self.fc(features)\n",
    "        return output, features\n",
    "\n",
    "class SelfSupervisedCancerModel(nn.Module):\n",
    "    \"\"\"SegResNet with self-supervised learning head for cancer classification\"\"\"\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SelfSupervisedCancerModel, self).__init__()\n",
    "        # Initialize SegResNet as backbone\n",
    "        # Modified to work with 1-channel input and small input size\n",
    "        self.backbone = SegResNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=2,  # This is the number of output channels\n",
    "            blocks_down=[3, 4, 23, 3],\n",
    "            blocks_up=[3, 6, 3],\n",
    "            upsample_mode=\"deconv\",\n",
    "            init_filters=32,\n",
    "        )\n",
    "        \n",
    "        # We know from the structure that the final conv layer outputs 2 channels\n",
    "        # Look at the print of self.backbone.conv_final showing Conv2d(8, 2, ...)\n",
    "        backbone_out_channels = 2\n",
    "        \n",
    "        # Replace classifier with our self-supervised head\n",
    "        self.ssl_head = SelfSupervisedHead(backbone_out_channels, num_classes)\n",
    "        \n",
    "        # Remove original classifier if needed\n",
    "        if hasattr(self.backbone, 'class_layers'):\n",
    "            self.backbone.class_layers = nn.Identity()\n",
    "        \n",
    "    def forward(self, x, return_features=False):\n",
    "        # Run through backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Apply self-supervised head\n",
    "        output, proj_features = self.ssl_head(features)\n",
    "        \n",
    "        if return_features:\n",
    "            return output, proj_features\n",
    "        return output\n",
    "\n",
    "# NTXent Loss for contrastive learning\n",
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Normalized Temperature-scaled Cross Entropy Loss for contrastive learning\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, features, labels):\n",
    "        # Normalize features\n",
    "        features = F.normalize(features, dim=1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        \n",
    "        # Create masks for positive and negative pairs\n",
    "        batch_size = features.shape[0]\n",
    "        mask = torch.zeros_like(similarity_matrix)\n",
    "        \n",
    "        # For each anchor, samples with same label are positive pairs\n",
    "        for i in range(batch_size):\n",
    "            for j in range(batch_size):\n",
    "                if i != j and labels[i] == labels[j]:\n",
    "                    mask[i, j] = 1.0\n",
    "        \n",
    "        # Remove self-similarity from the matrix\n",
    "        mask_self = torch.eye(batch_size, device=features.device)\n",
    "        mask_not_self = 1 - mask_self\n",
    "        similarity_matrix = similarity_matrix * mask_not_self\n",
    "        \n",
    "        # Create labels for contrastive loss\n",
    "        # For each row, indices with same label are positive pairs\n",
    "        pos_mask = mask.bool()\n",
    "        if pos_mask.sum() == 0:  # If no positive pairs, return 0\n",
    "            return torch.tensor(0.0, device=features.device)\n",
    "            \n",
    "        # Create labels for each anchor: the class of positive samples\n",
    "        contrastive_labels = torch.zeros(batch_size, device=features.device).long()\n",
    "        for i in range(batch_size):\n",
    "            pos_indices = pos_mask[i].nonzero(as_tuple=True)[0]\n",
    "            if len(pos_indices) > 0:\n",
    "                contrastive_labels[i] = pos_indices[0]\n",
    "                \n",
    "        # Calculate loss\n",
    "        loss = self.criterion(similarity_matrix, contrastive_labels)\n",
    "        return loss\n",
    "\n",
    "def create_data_loaders(embeddings_path, metadata_path, batch_size=32, test_size=0.2, random_state=42):\n",
    "    \"\"\"Create PyTorch DataLoaders for training and validation\"\"\"\n",
    "    # Create full dataset\n",
    "    full_dataset = EmbeddingsDataset(embeddings_path, metadata_path)\n",
    "    \n",
    "    # Split indices for train/val\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(full_dataset)),\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=[full_dataset.metadata['label'].iloc[i] for i in range(len(full_dataset))]\n",
    "    )\n",
    "    \n",
    "    # Create subset datasets\n",
    "    from torch.utils.data import Subset\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_model_with_logging(model, train_loader, val_loader, checkpoint_path:str,\n",
    "                             device, writer, num_epochs=10, learning_rate=0.001,\n",
    "                             temperature=0.07):\n",
    "    \"\"\"Train the cancer detection model with self-supervised learning and TensorBoard logging\"\"\"\n",
    "    # Define loss functions and optimizer\n",
    "    classification_criterion = nn.CrossEntropyLoss()\n",
    "    contrastive_criterion = NTXentLoss(temperature)  # Contrastive loss for self-supervision\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Improved learning rate scheduler - CosineAnnealingWarmRestarts\n",
    "    # This provides cyclical learning rates with warm restarts\n",
    "    # Good for avoiding local minima and finding better global minima\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=5,           # Restart every 5 epochs\n",
    "        T_mult=1,        # Keep the same cycle length\n",
    "        eta_min=1e-5     # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Only load scheduler if it's compatible with our current scheduler\n",
    "        try:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        except:\n",
    "            print(\"Warning: Couldn't load scheduler state from checkpoint (may be different type)\")\n",
    "            # Manually advance scheduler to match the epoch\n",
    "            for _ in range(checkpoint['epoch']):\n",
    "                scheduler.step()\n",
    "                \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        if 'best_val_loss' in checkpoint:\n",
    "            best_val_loss = checkpoint['best_val_loss']\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_auc = 0.0\n",
    "    best_model_weights = None\n",
    "    \n",
    "    # Use trange for epoch progress\n",
    "    epoch_iterator = trange(num_epochs, desc=\"Epochs\")\n",
    "    for epoch in epoch_iterator:\n",
    "        print(\"epoc: \", epoch)\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_class_loss = 0.0\n",
    "        train_ssl_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Use tqdm for batch progress in training\n",
    "        batch_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch_idx, (embeddings, labels) in enumerate(batch_iterator):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with features\n",
    "            outputs, features = model(embeddings, return_features=True)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = classification_criterion(outputs, labels)\n",
    "            \n",
    "            # Self-supervised contrastive loss\n",
    "            # Group features by class for positive pairs\n",
    "            pos_indices = (labels == 1).nonzero(as_tuple=True)[0]\n",
    "            neg_indices = (labels == 0).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # Only compute contrastive loss if we have samples from both classes\n",
    "            if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                pos_features = features[pos_indices]\n",
    "                neg_features = features[neg_indices]\n",
    "                \n",
    "                # Create positive and negative pairs for contrastive learning\n",
    "                all_features = torch.cat([pos_features, neg_features], dim=0)\n",
    "                all_labels = torch.cat([\n",
    "                    torch.ones(len(pos_indices), device=device),\n",
    "                    torch.zeros(len(neg_indices), device=device)\n",
    "                ])\n",
    "                \n",
    "                # Compute contrastive loss\n",
    "                ssl_loss = contrastive_criterion(all_features, all_labels)\n",
    "                \n",
    "                # Total loss (weighted combination)\n",
    "                loss = class_loss + 0.5 * ssl_loss\n",
    "                train_ssl_loss += ssl_loss.item() * embeddings.size(0)\n",
    "            else:\n",
    "                # If we don't have samples from both classes, just use classification loss\n",
    "                loss = class_loss\n",
    "                ssl_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * embeddings.size(0)\n",
    "            train_class_loss += class_loss.item() * embeddings.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            # Log batch-level metrics (every 10 batches)\n",
    "            if batch_idx % 10 == 0:\n",
    "                global_step = epoch * len(train_loader) + batch_idx\n",
    "                writer.add_scalar('Batch/Loss/train', loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/ClassLoss/train', class_loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/SSLLoss/train', ssl_loss.item(), global_step)\n",
    "                \n",
    "                # Add histograms of model parameters\n",
    "                if batch_idx % 50 == 0:\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            writer.add_histogram(f'Parameters/{name}', param.data, global_step)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_class_loss = train_class_loss / len(train_loader.dataset)\n",
    "        train_ssl_loss = train_ssl_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        \n",
    "        # Use tqdm for batch progress in validation\n",
    "        val_iterator = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_iterator:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(embeddings)\n",
    "                loss = classification_criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * embeddings.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Store for metrics calculation\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                all_probs.extend(probs)\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_iterator.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Calculate AUC and other metrics\n",
    "        from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, f1_score, confusion_matrix\n",
    "        val_auc = roc_auc_score(all_labels, all_probs)\n",
    "        val_ap = average_precision_score(all_labels, all_probs)\n",
    "        val_f1 = f1_score(all_labels, all_preds)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_auc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model_weights = model.state_dict().copy()\n",
    "            torch.save(best_model_weights, f\"{LOG_DIR}/best_model_epoch_{epoch}.pth\")\n",
    "            writer.add_text('Training', f'New best model saved at epoch {epoch} with AUC {best_val_auc:.4f}', epoch)\n",
    "        \n",
    "        # Update epoch progress bar with metrics\n",
    "        epoch_iterator.set_postfix({\n",
    "            \"train_loss\": f\"{train_loss:.4f}\", \n",
    "            \"train_acc\": f\"{train_acc:.4f}\",\n",
    "            \"val_loss\": f\"{val_loss:.4f}\", \n",
    "            \"val_acc\": f\"{val_acc:.4f}\", \n",
    "            \"val_auc\": f\"{val_auc:.4f}\"\n",
    "        })\n",
    "        \n",
    "        # Log epoch-level metrics to TensorBoard\n",
    "        writer.add_scalar('Epoch/Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Loss/val', val_loss, epoch)\n",
    "        writer.add_scalar('Epoch/ClassLoss/train', train_class_loss, epoch)\n",
    "        writer.add_scalar('Epoch/SSLLoss/train', train_ssl_loss, epoch)\n",
    "        writer.add_scalar('Epoch/Accuracy/train', train_acc, epoch)\n",
    "        writer.add_scalar('Epoch/Accuracy/val', val_acc, epoch)\n",
    "        writer.add_scalar('Epoch/AUC/val', val_auc, epoch)\n",
    "        writer.add_scalar('Epoch/AP/val', val_ap, epoch)\n",
    "        writer.add_scalar('Epoch/F1/val', val_f1, epoch)\n",
    "        writer.add_scalar('Epoch/Sensitivity/val', sensitivity, epoch)\n",
    "        writer.add_scalar('Epoch/Specificity/val', specificity, epoch)\n",
    "        writer.add_scalar('Epoch/LearningRate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        \n",
    "        # Log PR curve (once every few epochs)\n",
    "        if epoch % 2 == 0:\n",
    "            precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "            # Create figure\n",
    "            import matplotlib.pyplot as plt\n",
    "            fig = plt.figure()\n",
    "            plt.plot(recall, precision, marker='.', label=f'AP={val_ap:.3f}')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title(f'PR Curve - Epoch {epoch}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            # Add to tensorboard\n",
    "            writer.add_figure(f'PR_Curve/epoch_{epoch}', fig, epoch)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Add confusion matrix as figure\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            plt.imshow([[tn, fp], [fn, tp]], cmap='Blues', interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "            plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            thresh = (tn + fp + fn + tp) / 2\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    text = plt.text(j, i, [[tn, fp], [fn, tp]][i][j],\n",
    "                                    ha=\"center\", va=\"center\", color=\"white\" if [[tn, fp], [fn, tp]][i][j] > thresh else \"black\")\n",
    "            plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "            plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "            writer.add_figure(f'Confusion_Matrix/epoch_{epoch}', fig, epoch)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Log model graph with sample input\n",
    "    try:\n",
    "        sample_input = torch.rand(1, 1, 384, 1).to(device)\n",
    "        writer.add_graph(model, sample_input)\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't add model graph to TensorBoard: {e}\")\n",
    "        \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f26fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:50.700559Z",
     "iopub.status.busy": "2025-05-03T05:14:50.699733Z",
     "iopub.status.idle": "2025-05-03T05:14:50.705731Z",
     "shell.execute_reply": "2025-05-03T05:14:50.704878Z"
    },
    "papermill": {
     "duration": 0.014119,
     "end_time": "2025-05-03T05:14:50.707066",
     "exception": false,
     "start_time": "2025-05-03T05:14:50.692947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # First, save this code as a new cell to run after interrupting your current training\n",
    "# # Run this immediately after your training is interrupted at epoch 4\n",
    "\n",
    "# import torch\n",
    "\n",
    "# # 1. Create a checkpoint from your current model state\n",
    "# def create_checkpoint_from_model(model_path, output_checkpoint_path, current_epoch=4):\n",
    "#     \"\"\"\n",
    "#     Create a checkpoint file from an existing .pth model file\n",
    "#     \"\"\"\n",
    "#     # Load the model state dict\n",
    "#     model_state_dict = torch.load(model_path)\n",
    "    \n",
    "#     # Create model\n",
    "#     model = SelfSupervisedCancerModel()\n",
    "#     model.load_state_dict(model_state_dict)\n",
    "    \n",
    "#     # Create a new optimizer and scheduler (we'll have to reinitialize these)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "#         optimizer, \n",
    "#         T_0=5,           # Restart every 5 epochs\n",
    "#         T_mult=1,        # Keep the same cycle length\n",
    "#         eta_min=1e-6     # Minimum learning rate\n",
    "#     )\n",
    "    \n",
    "#     # If you've already trained for 4 epochs, advance the scheduler\n",
    "#     for _ in range(current_epoch):\n",
    "#         scheduler.step()\n",
    "    \n",
    "#     # Create checkpoint dictionary\n",
    "#     checkpoint = {\n",
    "#         'epoch': current_epoch,\n",
    "#         'model_state_dict': model_state_dict,\n",
    "#         'optimizer_state_dict': optimizer.state_dict(),\n",
    "#         'scheduler_state_dict': scheduler.state_dict(),\n",
    "#         'best_val_loss': float('inf'),  # We don't know this, so use a default\n",
    "#         'train_loss': 0.0,              # We don't have this info\n",
    "#         'val_loss': 0.0,                # We don't have this info\n",
    "#         'accuracy': 0.0                 # We don't have this info\n",
    "#     }\n",
    "    \n",
    "#     # Save the checkpoint\n",
    "#     torch.save(checkpoint, output_checkpoint_path)\n",
    "#     print(f\"Created checkpoint at {output_checkpoint_path} from model at {model_path}\")\n",
    "    \n",
    "#     return checkpoint\n",
    "\n",
    "# # Create a checkpoint from your saved model\n",
    "# model_path = \"/kaggle/input/histopathology-cancer-classify/pytorch/midsize_model/1/best_model_epoch_2.pth\"  # Your current saved model\n",
    "# checkpoint_path = \"/kaggle/working/checkpoint.pth\"\n",
    "# checkpoint = create_checkpoint_from_model(model_path, checkpoint_path, current_epoch=2)\n",
    "\n",
    "# print(\"Checkpoint created! Download this file to resume training later.\")\n",
    "# print(\"To resume training, upload this checkpoint file and run the updated training code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ebf07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:50.717324Z",
     "iopub.status.busy": "2025-05-03T05:14:50.716913Z",
     "iopub.status.idle": "2025-05-03T05:14:50.722444Z",
     "shell.execute_reply": "2025-05-03T05:14:50.721975Z"
    },
    "papermill": {
     "duration": 0.011417,
     "end_time": "2025-05-03T05:14:50.723454",
     "exception": false,
     "start_time": "2025-05-03T05:14:50.712037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Import TensorBoard SummaryWriter\n",
    "#     from torch.utils.tensorboard import SummaryWriter\n",
    "    \n",
    "#     # Define paths\n",
    "#     EMBEDDINGS_PATH = \"/kaggle/input/histopath-cancer-embeddings/embeddings/\"\n",
    "#     METADATA_PATH = \"/kaggle/input/histopath-cancer-embeddings/metadata/\"\n",
    "#     LOG_DIR = \"/kaggle/working/tensorboard_logs\"\n",
    "    \n",
    "#     # Create TensorBoard writer\n",
    "#     writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "#     print(f\"TensorBoard logs will be saved to: {LOG_DIR}\")\n",
    "    \n",
    "#     # Set device\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Create data loaders\n",
    "#     train_loader, val_loader = create_data_loaders(\n",
    "#         EMBEDDINGS_PATH, \n",
    "#         METADATA_PATH,\n",
    "#         batch_size=512\n",
    "#     )\n",
    "#     print(\"data loaded\")\n",
    "\n",
    "#     init_channels = 32\n",
    "#     # Create model\n",
    "#     model = SelfSupervisedCancerModel()\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     # Create a modified train_model function with TensorBoard logging\n",
    "\n",
    "#     checkpoint_path = \"/kaggle/working/checkpoint.pth\"\n",
    "#     # Train model with self-supervised learning and TensorBoard logging\n",
    "#     trained_model = train_model_with_logging(\n",
    "#         model=model,\n",
    "#         train_loader=train_loader,\n",
    "#         val_loader=val_loader,\n",
    "#         device=device,\n",
    "#         writer=writer,\n",
    "#         num_epochs=3,\n",
    "#         temperature=0.2,  # Temperature for contrastive loss\n",
    "#         checkpoint_path=\"/kaggle/working/checkpoint.pth\"\n",
    "#     )\n",
    "    \n",
    "#     # Add embedding visualization to TensorBoard\n",
    "#     print(\"\\nAdding embeddings to TensorBoard...\")\n",
    "#     # Get a sample of embeddings\n",
    "#     try:\n",
    "#         # Create dataset for visualization\n",
    "#         vis_dataset = EmbeddingsDataset(EMBEDDINGS_PATH, METADATA_PATH)\n",
    "#         vis_loader = DataLoader(vis_dataset, batch_size=128, shuffle=False)\n",
    "        \n",
    "#         # Extract features using model\n",
    "#         all_features = []\n",
    "#         all_labels = []\n",
    "#         all_images = []  # We don't have actual images, so we'll create simple representations\n",
    "        \n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for i, (embeddings, labels) in enumerate(vis_loader):\n",
    "#                 if i >= 10:  # Limit to 10 batches for visualization\n",
    "#                     break\n",
    "                    \n",
    "#                 embeddings = embeddings.to(device)\n",
    "#                 _, features = model(embeddings, return_features=True)\n",
    "#                 all_features.append(features.cpu())\n",
    "#                 all_labels.extend(labels.numpy())\n",
    "                \n",
    "#                 # Create simple image representations (1=white, 0=black)\n",
    "#                 for label in labels:\n",
    "#                     img = torch.ones(3, 32, 32) if label == 1 else torch.zeros(3, 32, 32)\n",
    "#                     all_images.append(img)\n",
    "        \n",
    "#         # Concatenate features\n",
    "#         if all_features:\n",
    "#             all_features = torch.cat(all_features)\n",
    "            \n",
    "#             # Convert labels to strings for visualization\n",
    "#             label_names = ['Negative' if l == 0 else 'Positive' for l in all_labels]\n",
    "            \n",
    "#             # Add embeddings to TensorBoard\n",
    "#             writer.add_embedding(\n",
    "#                 all_features, \n",
    "#                 metadata=label_names,\n",
    "#                 label_img=torch.stack(all_images) if all_images else None,\n",
    "#                 global_step=0\n",
    "#             )\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error adding embeddings to TensorBoard: {e}\")\n",
    "    \n",
    "#     # Save the model\n",
    "#     torch.save(trained_model.state_dict(), \"/kaggle/working/cancer_detector_model.pth\")\n",
    "#     print(\"Model saved to /kaggle/working/cancer_detector_model.pth\")\n",
    "    \n",
    "#     # Close TensorBoard writer\n",
    "#     writer.close()\n",
    "#     print(\"TensorBoard logging complete\")\n",
    "    \n",
    "#     # Example of inference and feature extraction\n",
    "#     print(\"\\nExample of model inference:\")\n",
    "#     try:\n",
    "#         # Load dataset\n",
    "#         dataset = EmbeddingsDataset(EMBEDDINGS_PATH, METADATA_PATH)\n",
    "        \n",
    "#         # Get a sample embedding\n",
    "#         sample_id = dataset.master_metadata['file_id'].iloc[0]\n",
    "#         embedding_data, true_label = dataset.get_embedding(sample_id)\n",
    "        \n",
    "#         # Prepare for inference\n",
    "#         embedding_tensor = torch.tensor(embedding_data, dtype=torch.float32).view(1, 1, 384, 1).to(device)\n",
    "        \n",
    "#         # Run inference\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             # Get both output and features for visualization\n",
    "#             output, features = model(embedding_tensor, return_features=True)\n",
    "#             probs = torch.softmax(output, dim=1)\n",
    "#             predicted_class = torch.argmax(probs, dim=1).item()\n",
    "#             confidence = probs[0][predicted_class].item()\n",
    "        \n",
    "#         print(f\"Sample ID: {sample_id}\")\n",
    "#         print(f\"True label: {true_label} ({'Positive' if true_label == 1 else 'Negative'})\")\n",
    "#         print(f\"Predicted class: {predicted_class} ({'Positive' if predicted_class == 1 else 'Negative'})\")\n",
    "#         print(f\"Confidence: {confidence:.4f}\")\n",
    "        \n",
    "#         # Extract features for all samples for visualization/clustering\n",
    "#         print(\"\\nExtracting features for all samples...\")\n",
    "#         all_features = []\n",
    "#         all_labels = []\n",
    "        \n",
    "#         eval_dataset = EmbeddingsDataset(EMBEDDINGS_PATH, METADATA_PATH)\n",
    "#         eval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for embeddings, labels in eval_loader:\n",
    "#                 embeddings = embeddings.to(device)\n",
    "#                 _, batch_features = model(embeddings, return_features=True)\n",
    "#                 all_features.append(batch_features.cpu().numpy())\n",
    "#                 all_labels.append(labels.cpu().numpy())\n",
    "        \n",
    "#         all_features = np.vstack(all_features)\n",
    "#         all_labels = np.concatenate(all_labels)\n",
    "        \n",
    "#         # Save features for downstream visualization/analysis\n",
    "#         np.savez(\"/kaggle/working/cancer_features.npz\", \n",
    "#                  features=all_features, \n",
    "#                  labels=all_labels)\n",
    "        \n",
    "#         print(f\"Extracted features shape: {all_features.shape}\")\n",
    "#         print(f\"Features saved to /kaggle/working/cancer_features.npz\")\n",
    "        \n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during inference: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858cea7",
   "metadata": {
    "papermill": {
     "duration": 0.005529,
     "end_time": "2025-05-03T05:14:50.735527",
     "exception": false,
     "start_time": "2025-05-03T05:14:50.729998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1266fb48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:50.748817Z",
     "iopub.status.busy": "2025-05-03T05:14:50.748615Z",
     "iopub.status.idle": "2025-05-03T05:14:50.760695Z",
     "shell.execute_reply": "2025-05-03T05:14:50.760012Z"
    },
    "papermill": {
     "duration": 0.019615,
     "end_time": "2025-05-03T05:14:50.761731",
     "exception": false,
     "start_time": "2025-05-03T05:14:50.742116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing distributed_training_addon.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile distributed_training_addon.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from utils import *\n",
    "\n",
    "def init_distributed():\n",
    "    \"\"\"Initialize distributed training environment\"\"\"\n",
    "    # Initializes the distributed backend which will take care of synchronizing nodes/GPUs\n",
    "    dist_url = \"env://\"  # default\n",
    "\n",
    "    # only works with torch.distributed.launch // torch.run\n",
    "    rank = int(os.environ.get(\"RANK\", \"0\"))\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', \"1\"))\n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', \"0\"))\n",
    "\n",
    "    if world_size > 1:\n",
    "        dist.init_process_group(\n",
    "            backend=\"nccl\",\n",
    "            init_method=dist_url,\n",
    "            world_size=world_size,\n",
    "            rank=rank)\n",
    "\n",
    "        # this will make all .cuda() calls work properly\n",
    "        torch.cuda.set_device(local_rank)\n",
    "\n",
    "        # synchronizes all the threads to reach this point before moving on\n",
    "        dist.barrier()\n",
    "        return True, rank, local_rank, world_size\n",
    "    else:\n",
    "        print(\"Not running in distributed mode\")\n",
    "        return False, 0, 0, 1\n",
    "\n",
    "\n",
    "def create_distributed_data_loaders(embeddings_path, metadata_path, rank, world_size, batch_size=256, test_size=0.2, random_state=42):\n",
    "    \"\"\"Create PyTorch DataLoaders for distributed training\"\"\"\n",
    "    # Create full dataset\n",
    "    full_dataset = EmbeddingsDataset(embeddings_path, metadata_path)\n",
    "    \n",
    "    # Split indices for train/val\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(full_dataset)),\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=[full_dataset.metadata['label'].iloc[i] for i in range(len(full_dataset))]\n",
    "    )\n",
    "    \n",
    "    # Create subset datasets\n",
    "    from torch.utils.data import Subset\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(full_dataset, val_indices)\n",
    "    \n",
    "    # Create distributed samplers\n",
    "    train_sampler = DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=world_size,\n",
    "        rank=rank,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_sampler = DistributedSampler(\n",
    "        val_dataset,\n",
    "        num_replicas=world_size,\n",
    "        rank=rank,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Create data loaders with distributed samplers\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Don't shuffle here - sampler does it\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        sampler=train_sampler\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Don't shuffle here\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        sampler=val_sampler\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, train_sampler\n",
    "\n",
    "\n",
    "def train_distributed_model(model, train_loader, val_loader, train_sampler, checkpoint_path, checkpoint_dir,\n",
    "                            device, writer, rank, local_rank, is_distributed,\n",
    "                            num_epochs=10, learning_rate=0.001, temperature=0.07):\n",
    "    \"\"\"Distributed training of the cancer detection model\"\"\"\n",
    "    \n",
    "    # Wrap model with DistributedDataParallel if using distributed training\n",
    "    if is_distributed:\n",
    "        # Convert BatchNorm to SyncBatchNorm for better stats across GPUs\n",
    "        model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "        model = DistributedDataParallel(model, device_ids=[local_rank])\n",
    "        model_without_ddp = model.module\n",
    "    else:\n",
    "        model_without_ddp = model\n",
    "    \n",
    "    # Define loss functions and optimizer\n",
    "    classification_criterion = nn.CrossEntropyLoss()\n",
    "    contrastive_criterion = NTXentLoss(temperature)  # Contrastive loss for self-supervision\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Improved learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, \n",
    "        T_0=5,           # Restart every 5 epochs\n",
    "        T_mult=1,        # Keep the same cycle length\n",
    "        eta_min=1e-5     # Minimum learning rate\n",
    "    )\n",
    "\n",
    "    # Resume from checkpoint if exists\n",
    "    start_epoch = 0\n",
    "    best_val_auc = 0.0\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        if is_distributed:\n",
    "            model_without_ddp.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Only load scheduler if it's compatible with our current scheduler\n",
    "        try:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        except:\n",
    "            print(\"Warning: Couldn't load scheduler state from checkpoint (may be different type)\")\n",
    "            # Manually advance scheduler to match the epoch\n",
    "            for _ in range(checkpoint['epoch']):\n",
    "                scheduler.step()\n",
    "                \n",
    "        start_epoch = checkpoint['epoch']\n",
    "        if 'best_val_auc' in checkpoint:\n",
    "            best_val_auc = checkpoint['best_val_auc']\n",
    "        if rank == 0:\n",
    "            print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "    # Training loop\n",
    "    best_model_weights = None\n",
    "    \n",
    "    from tqdm.notebook import trange, tqdm\n",
    "    # Only show progress bar on main process\n",
    "    if rank == 0:\n",
    "        epoch_iterator = trange(start_epoch, num_epochs, desc=\"Epochs\")\n",
    "    else:\n",
    "        epoch_iterator = range(start_epoch, num_epochs)\n",
    "        \n",
    "    for epoch in epoch_iterator:\n",
    "        # Set sampler epoch for proper shuffling\n",
    "        if is_distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "            \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_class_loss = 0.0\n",
    "        train_ssl_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # Use tqdm for batch progress in training only on rank 0\n",
    "        if rank == 0:\n",
    "            batch_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        else:\n",
    "            batch_iterator = train_loader\n",
    "            \n",
    "        for batch_idx, (embeddings, labels) in enumerate(batch_iterator):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with features\n",
    "            outputs, features = model(embeddings, return_features=True)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = classification_criterion(outputs, labels)\n",
    "            \n",
    "            # Self-supervised contrastive loss\n",
    "            # Group features by class for positive pairs\n",
    "            pos_indices = (labels == 1).nonzero(as_tuple=True)[0]\n",
    "            neg_indices = (labels == 0).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            # Only compute contrastive loss if we have samples from both classes\n",
    "            if len(pos_indices) > 0 and len(neg_indices) > 0:\n",
    "                pos_features = features[pos_indices]\n",
    "                neg_features = features[neg_indices]\n",
    "                \n",
    "                # Create positive and negative pairs for contrastive learning\n",
    "                all_features = torch.cat([pos_features, neg_features], dim=0)\n",
    "                all_labels = torch.cat([\n",
    "                    torch.ones(len(pos_indices), device=device),\n",
    "                    torch.zeros(len(neg_indices), device=device)\n",
    "                ])\n",
    "                \n",
    "                # Compute contrastive loss\n",
    "                ssl_loss = contrastive_criterion(all_features, all_labels)\n",
    "                \n",
    "                # Total loss (weighted combination)\n",
    "                loss = class_loss + 0.5 * ssl_loss\n",
    "                train_ssl_loss += ssl_loss.item() * embeddings.size(0)\n",
    "            else:\n",
    "                # If we don't have samples from both classes, just use classification loss\n",
    "                loss = class_loss\n",
    "                ssl_loss = torch.tensor(0.0)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * embeddings.size(0)\n",
    "            train_class_loss += class_loss.item() * embeddings.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar with current loss (only on rank 0)\n",
    "            if rank == 0 and isinstance(batch_iterator, tqdm):\n",
    "                batch_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "            # Log batch-level metrics (every 10 batches) - only on rank 0\n",
    "            if rank == 0 and batch_idx % 10 == 0:\n",
    "                global_step = epoch * len(train_loader) + batch_idx\n",
    "                writer.add_scalar('Batch/Loss/train', loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/ClassLoss/train', class_loss.item(), global_step)\n",
    "                writer.add_scalar('Batch/SSLLoss/train', ssl_loss.item(), global_step)\n",
    "                \n",
    "                # Add histograms of model parameters\n",
    "                if batch_idx % 50 == 0:\n",
    "                    for name, param in model_without_ddp.named_parameters():\n",
    "                        if param.requires_grad:\n",
    "                            writer.add_histogram(f'Parameters/{name}', param.data, global_step)\n",
    "        \n",
    "        # Reduce metrics across all processes for accurate stats\n",
    "        if is_distributed:\n",
    "            # Create tensors on device for reduction\n",
    "            train_loss_tensor = torch.tensor([train_loss], device=device)\n",
    "            train_class_loss_tensor = torch.tensor([train_class_loss], device=device)\n",
    "            train_ssl_loss_tensor = torch.tensor([train_ssl_loss], device=device)\n",
    "            train_correct_tensor = torch.tensor([train_correct], device=device)\n",
    "            train_total_tensor = torch.tensor([train_total], device=device)\n",
    "            \n",
    "            # All-reduce\n",
    "            dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(train_class_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(train_ssl_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(train_correct_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(train_total_tensor, op=dist.ReduceOp.SUM)\n",
    "            \n",
    "            # Update variables with reduced values\n",
    "            train_loss = train_loss_tensor.item()\n",
    "            train_class_loss = train_class_loss_tensor.item()\n",
    "            train_ssl_loss = train_ssl_loss_tensor.item()\n",
    "            train_correct = train_correct_tensor.item()\n",
    "            train_total = train_total_tensor.item()\n",
    "        \n",
    "        train_loss = train_loss / train_total\n",
    "        train_class_loss = train_class_loss / train_total\n",
    "        train_ssl_loss = train_ssl_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "        all_preds = []\n",
    "        \n",
    "        # Use tqdm for batch progress in validation (only on rank 0)\n",
    "        if rank == 0:\n",
    "            val_iterator = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        else:\n",
    "            val_iterator = val_loader\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_iterator:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(embeddings)\n",
    "                loss = classification_criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * embeddings.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Store for metrics calculation\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                all_probs.extend(probs)\n",
    "                \n",
    "                # Update progress bar (only on rank 0)\n",
    "                if rank == 0 and isinstance(val_iterator, tqdm): \n",
    "                    val_iterator.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        # Reduce validation metrics across all processes\n",
    "        if is_distributed:\n",
    "            # Create tensors on device for reduction\n",
    "            val_loss_tensor = torch.tensor([val_loss], device=device)\n",
    "            val_correct_tensor = torch.tensor([val_correct], device=device)\n",
    "            val_total_tensor = torch.tensor([val_total], device=device)\n",
    "            \n",
    "            # All-reduce\n",
    "            dist.all_reduce(val_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(val_correct_tensor, op=dist.ReduceOp.SUM)\n",
    "            dist.all_reduce(val_total_tensor, op=dist.ReduceOp.SUM)\n",
    "            \n",
    "            # Update variables with reduced values\n",
    "            val_loss = val_loss_tensor.item()\n",
    "            val_correct = val_correct_tensor.item()\n",
    "            val_total = val_total_tensor.item()\n",
    "            \n",
    "            # Gather labels and predictions from all processes\n",
    "            # First, convert lists to tensors\n",
    "            all_labels_tensor = torch.tensor(all_labels, device=device)\n",
    "            all_probs_tensor = torch.tensor(all_probs, device=device)\n",
    "            all_preds_tensor = torch.tensor(all_preds, device=device)\n",
    "            \n",
    "            # Get sizes from all processes\n",
    "            size_tensor = torch.tensor([len(all_labels)], device=device)\n",
    "            # Get world size from the current process group\n",
    "            current_world_size = dist.get_world_size()\n",
    "            sizes = [torch.zeros_like(size_tensor) for _ in range(current_world_size)]\n",
    "            dist.all_gather(sizes, size_tensor)\n",
    "            \n",
    "            # Create tensors to gather into\n",
    "            max_size = max(size.item() for size in sizes)\n",
    "            # Pad tensors to max size\n",
    "            padded_labels = torch.zeros(max_size, device=device)\n",
    "            padded_probs = torch.zeros(max_size, device=device)\n",
    "            padded_preds = torch.zeros(max_size, device=device)\n",
    "            \n",
    "            # Copy data to padded tensors\n",
    "            padded_labels[:len(all_labels)] = all_labels_tensor\n",
    "            padded_probs[:len(all_probs)] = all_probs_tensor\n",
    "            padded_preds[:len(all_preds)] = all_preds_tensor\n",
    "            \n",
    "            # Create list of tensors to gather into\n",
    "            gathered_labels = [torch.zeros_like(padded_labels) for _ in range(current_world_size)]\n",
    "            gathered_probs = [torch.zeros_like(padded_probs) for _ in range(current_world_size)]\n",
    "            gathered_preds = [torch.zeros_like(padded_preds) for _ in range(current_world_size)]\n",
    "            \n",
    "            # Gather data from all processes\n",
    "            dist.all_gather(gathered_labels, padded_labels)\n",
    "            dist.all_gather(gathered_probs, padded_probs)\n",
    "            dist.all_gather(gathered_preds, padded_preds)\n",
    "            \n",
    "            # Convert gathered tensors back to lists\n",
    "            all_labels = []\n",
    "            all_probs = []\n",
    "            all_preds = []\n",
    "            \n",
    "            for i, size in enumerate(sizes):\n",
    "                all_labels.extend(gathered_labels[i][:size].cpu().numpy())\n",
    "                all_probs.extend(gathered_probs[i][:size].cpu().numpy())\n",
    "                all_preds.extend(gathered_preds[i][:size].cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        print(\"val loss: \", val_loss)\n",
    "        print(\"val acc: \", val_acc)\n",
    "        # Calculate AUC and other metrics (only on rank 0)\n",
    "        if rank == 0:\n",
    "            from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, f1_score, confusion_matrix\n",
    "            val_auc = roc_auc_score(all_labels, all_probs)\n",
    "            val_ap = average_precision_score(all_labels, all_probs)\n",
    "            val_f1 = f1_score(all_labels, all_preds)\n",
    "            tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(val_auc)\n",
    "            \n",
    "            if not os.path.exists(os.path.dirname(checkpoint_dir)):\n",
    "                os.makedirs(os.path.dirname(checkpoint_dir))\n",
    "                \n",
    "            # Save the checkpoint for this epoch\n",
    "            epoch_checkpoint_path = f\"{os.path.dirname(checkpoint_dir)}/model_epoch_{epoch}.pth\"\n",
    "            print(\"epoch_checkpoint_path: \", epoch_checkpoint_path)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model_without_ddp.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_auc': val_auc\n",
    "            }, epoch_checkpoint_path)\n",
    "            writer.add_text('Training', f'Model saved at epoch {epoch}', epoch)\n",
    "            \n",
    "            # If this is also the best model, save it separately\n",
    "            if val_auc > best_val_auc:\n",
    "                best_val_auc = val_auc\n",
    "                best_model_weights = model_without_ddp.state_dict().copy()\n",
    "                best_model_path = f\"{os.path.dirname(checkpoint_dir)}/best_model_epoch_{epoch}.pth\"\n",
    "                torch.save(best_model_weights, best_model_path)\n",
    "                writer.add_text('Training', f'New best model saved at epoch {epoch} with AUC {best_val_auc:.4f}', epoch)\n",
    "                \n",
    "                # Also update the latest checkpoint for resuming training\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model_without_ddp.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'best_val_auc': best_val_auc\n",
    "                }, checkpoint_path)\n",
    "            \n",
    "            # Update epoch progress bar with metrics (only on rank 0)\n",
    "            if isinstance(epoch_iterator, tqdm):\n",
    "                epoch_iterator.set_postfix({\n",
    "                    \"train_loss\": f\"{train_loss:.4f}\", \n",
    "                    \"train_acc\": f\"{train_acc:.4f}\",\n",
    "                    \"val_loss\": f\"{val_loss:.4f}\", \n",
    "                    \"val_acc\": f\"{val_acc:.4f}\", \n",
    "                    \"val_auc\": f\"{val_auc:.4f}\"\n",
    "                })\n",
    "            \n",
    "            # Log epoch-level metrics to TensorBoard (only on rank 0)\n",
    "            writer.add_scalar('Epoch/Loss/train', train_loss, epoch)\n",
    "            writer.add_scalar('Epoch/Loss/val', val_loss, epoch)\n",
    "            writer.add_scalar('Epoch/ClassLoss/train', train_class_loss, epoch)\n",
    "            writer.add_scalar('Epoch/SSLLoss/train', train_ssl_loss, epoch)\n",
    "            writer.add_scalar('Epoch/Accuracy/train', train_acc, epoch)\n",
    "            writer.add_scalar('Epoch/Accuracy/val', val_acc, epoch)\n",
    "            writer.add_scalar('Epoch/AUC/val', val_auc, epoch)\n",
    "            writer.add_scalar('Epoch/AP/val', val_ap, epoch)\n",
    "            writer.add_scalar('Epoch/F1/val', val_f1, epoch)\n",
    "            writer.add_scalar('Epoch/Sensitivity/val', sensitivity, epoch)\n",
    "            writer.add_scalar('Epoch/Specificity/val', specificity, epoch)\n",
    "            writer.add_scalar('Epoch/LearningRate', optimizer.param_groups[0]['lr'], epoch)\n",
    "            \n",
    "            # Log PR curve (once every few epochs)\n",
    "            if epoch % 2 == 0:\n",
    "                precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "                # Create figure\n",
    "                import matplotlib.pyplot as plt\n",
    "                fig = plt.figure()\n",
    "                plt.plot(recall, precision, marker='.', label=f'AP={val_ap:.3f}')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.title(f'PR Curve - Epoch {epoch}')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                # Add to tensorboard\n",
    "                writer.add_figure(f'PR_Curve/epoch_{epoch}', fig, epoch)\n",
    "                plt.close(fig)\n",
    "                \n",
    "                # Add confusion matrix as figure\n",
    "                fig = plt.figure(figsize=(8, 6))\n",
    "                plt.imshow([[tn, fp], [fn, tp]], cmap='Blues', interpolation='nearest')\n",
    "                plt.colorbar()\n",
    "                plt.title(f'Confusion Matrix - Epoch {epoch}')\n",
    "                plt.xlabel('Predicted')\n",
    "                plt.ylabel('Actual')\n",
    "                thresh = (tn + fp + fn + tp) / 2\n",
    "                for i in range(2):\n",
    "                    for j in range(2):\n",
    "                        text = plt.text(j, i, [[tn, fp], [fn, tp]][i][j],\n",
    "                                        ha=\"center\", va=\"center\", color=\"white\" if [[tn, fp], [fn, tp]][i][j] > thresh else \"black\")\n",
    "                plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "                plt.yticks([0, 1], ['Negative', 'Positive'])\n",
    "                writer.add_figure(f'Confusion_Matrix/epoch_{epoch}', fig, epoch)\n",
    "                plt.close(fig)\n",
    "        \n",
    "        # Wait for all processes to complete epoch before continuing\n",
    "        if is_distributed:\n",
    "            dist.barrier()\n",
    "    \n",
    "    # Load best model weights (only if we have them and are on rank 0)\n",
    "    if rank == 0 and best_model_weights is not None:\n",
    "        model_without_ddp.load_state_dict(best_model_weights)\n",
    "        \n",
    "    return model_without_ddp if is_distributed else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58217c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:50.771943Z",
     "iopub.status.busy": "2025-05-03T05:14:50.771423Z",
     "iopub.status.idle": "2025-05-03T05:14:51.733100Z",
     "shell.execute_reply": "2025-05-03T05:14:51.732160Z"
    },
    "papermill": {
     "duration": 0.968011,
     "end_time": "2025-05-03T05:14:51.734726",
     "exception": false,
     "start_time": "2025-05-03T05:14:50.766715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot remove '/kaggle/input/histopathology-cancer-classify/pytorch/default/2/checkpoint.pth': Read-only file system\r\n"
     ]
    }
   ],
   "source": [
    "!mv /kaggle/input/histopathology-cancer-classify/pytorch/default/2/checkpoint.pth /kaggle/working/checkpoint.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b5e4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:51.751037Z",
     "iopub.status.busy": "2025-05-03T05:14:51.750753Z",
     "iopub.status.idle": "2025-05-03T05:14:51.757403Z",
     "shell.execute_reply": "2025-05-03T05:14:51.756679Z"
    },
    "papermill": {
     "duration": 0.016124,
     "end_time": "2025-05-03T05:14:51.758475",
     "exception": false,
     "start_time": "2025-05-03T05:14:51.742351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kaggle_distributed_runner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kaggle_distributed_runner.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import *\n",
    "from distributed_training_addon import *\n",
    "\n",
    "# Define paths\n",
    "EMBEDDINGS_PATH = \"/kaggle/input/histopath-cancer-embeddings/embeddings/\"\n",
    "METADATA_PATH = \"/kaggle/input/histopath-cancer-embeddings/metadata/\"\n",
    "LOG_DIR = \"/kaggle/working/tensorboard_logs/\"\n",
    "CHECKPOINT_PATH = \"/kaggle/working/checkpoint.pth\"\n",
    "CHECKPOINT_DIR = \"/kaggle/working/checkpoint_dir/\"\n",
    "\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Initialize distributed environment\n",
    "is_distributed, rank, local_rank, world_size = init_distributed()\n",
    "print(f\"Distributed: {is_distributed}, Rank: {rank}, Local Rank: {local_rank}, World Size: {world_size}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(f\"cuda:{local_rank}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create TensorBoard writer only on main process\n",
    "writer = SummaryWriter(log_dir=LOG_DIR) if rank == 0 else None\n",
    "if rank == 0:\n",
    "    print(f\"TensorBoard logs will be saved to: {LOG_DIR}\")\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Create distributed data loaders\n",
    "train_loader, val_loader, train_sampler = create_distributed_data_loaders(\n",
    "    EMBEDDINGS_PATH, \n",
    "    METADATA_PATH,\n",
    "    rank=rank,\n",
    "    world_size=world_size,\n",
    "    batch_size= 512 if is_distributed else 512  # Scale batch size by number of GPUs\n",
    ")\n",
    "print(f\"Rank {rank}: Data loaders created\")\n",
    "\n",
    "# Create model\n",
    "model = SelfSupervisedCancerModel()\n",
    "model = model.to(device)\n",
    "print(f\"Rank {rank}: Model created and moved to device\")\n",
    "\n",
    "# Train model with distributed training\n",
    "trained_model = train_distributed_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    train_sampler=train_sampler,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    rank=rank,\n",
    "    local_rank=local_rank,\n",
    "    is_distributed=is_distributed,\n",
    "    num_epochs=8,\n",
    "    temperature=0.12,  # Temperature for contrastive loss\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    checkpoint_dir=CHECKPOINT_DIR\n",
    ")\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"Training complete\")\n",
    "    # Save the model\n",
    "    torch.save(trained_model.state_dict(), \"/kaggle/working/cancer_detector_model.pth\")\n",
    "    print(\"Model saved to /kaggle/working/cancer_detector_model.pth\")\n",
    "    \n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "# Clean up distributed processes\n",
    "if is_distributed:\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "# Example of inference (run only on one process)\n",
    "if rank == 0:\n",
    "    print(\"\\nExample of model inference:\")\n",
    "    try:\n",
    "        # Load dataset\n",
    "        dataset = EmbeddingsDataset(EMBEDDINGS_PATH, METADATA_PATH)\n",
    "        \n",
    "        # Get a sample embedding\n",
    "        sample_id = dataset.master_metadata['file_id'].iloc[0]\n",
    "        embedding_data, true_label = dataset.get_embedding(sample_id)\n",
    "        \n",
    "        # Prepare for inference\n",
    "        embedding_tensor = torch.tensor(embedding_data, dtype=torch.float32).view(1, 1, 384, 1).to(device)\n",
    "        \n",
    "        # Run inference\n",
    "        trained_model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get both output and features for visualization\n",
    "            output, features = trained_model(embedding_tensor, return_features=True)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            predicted_class = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0][predicted_class].item()\n",
    "        \n",
    "        print(f\"Sample ID: {sample_id}\")\n",
    "        print(f\"True label: {true_label} ({'Positive' if true_label == 1 else 'Negative'})\")\n",
    "        print(f\"Predicted class: {predicted_class} ({'Positive' if predicted_class == 1 else 'Negative'})\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91b6899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:51.768643Z",
     "iopub.status.busy": "2025-05-03T05:14:51.768433Z",
     "iopub.status.idle": "2025-05-03T05:14:51.772015Z",
     "shell.execute_reply": "2025-05-03T05:14:51.771370Z"
    },
    "papermill": {
     "duration": 0.010636,
     "end_time": "2025-05-03T05:14:51.773121",
     "exception": false,
     "start_time": "2025-05-03T05:14:51.762485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6087386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:51.782368Z",
     "iopub.status.busy": "2025-05-03T05:14:51.781836Z",
     "iopub.status.idle": "2025-05-03T05:14:51.787280Z",
     "shell.execute_reply": "2025-05-03T05:14:51.786603Z"
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2025-05-03T05:14:51.788333",
     "exception": false,
     "start_time": "2025-05-03T05:14:51.777232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing launch_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile launch_training.py\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Script to launch distributed training on Kaggle T4x2 environment\n",
    "    This should be run with torchrun or torch.distributed.launch\n",
    "    \"\"\"\n",
    "    # The actual training code will be imported by each worker process\n",
    "    print(\"Launching distributed training with torchrun...\")\n",
    "    world_size = torch.cuda.device_count()\n",
    "    print(f\"World size: {world_size}\")\n",
    "    \n",
    "    # Run the main script with torchrun\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"torch.distributed.run\",\n",
    "        f\"--nproc_per_node={world_size}\",\n",
    "        \"kaggle_distributed_runner.py\"\n",
    "    ]\n",
    "    \n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    \n",
    "    # Stream output in real-time\n",
    "    for line in process.stdout:\n",
    "        print(line, end=\"\")\n",
    "    \n",
    "    process.wait()\n",
    "    return process.returncode\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Entry point for the script\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4d858c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:14:51.797143Z",
     "iopub.status.busy": "2025-05-03T05:14:51.796754Z",
     "iopub.status.idle": "2025-05-03T08:32:17.045242Z",
     "shell.execute_reply": "2025-05-03T08:32:17.044120Z"
    },
    "papermill": {
     "duration": 11845.254647,
     "end_time": "2025-05-03T08:32:17.046915",
     "exception": false,
     "start_time": "2025-05-03T05:14:51.792268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "Launching distributed training with torchrun...\r\n",
      "World size: 2\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\r\n",
      "    from tensorboard.compat import notf  # noqa: F401\r\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\r\n",
      "    from tensorboard.compat import notf  # noqa: F401\r\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "Available GPUs: 2\r\n",
      "GPU 0: Tesla T4\r\n",
      "GPU 1: Tesla T4\r\n",
      "Available GPUs: 2\r\n",
      "GPU 0: Tesla T4\r\n",
      "GPU 1: Tesla T4\r\n",
      "[rank0]:[W503 05:15:14.687079964 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "[rank1]:[W503 05:15:14.687079734 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\r\n",
      "Distributed: True, Rank: 1, Local Rank: 1, World Size: 2\r\n",
      "Distributed: True, Rank: 0, Local Rank: 0, World Size: 2\r\n",
      "Using device: cuda:1\r\n",
      "Using device: cuda:0\r\n",
      "TensorBoard logs will be saved to: /kaggle/working/tensorboard_logs/\r\n",
      "Rank 0: Data loaders created\r\n",
      "Rank 1: Data loaders created\r\n",
      "Rank 0: Model created and moved to device\r\n",
      "Rank 1: Model created and moved to device\r\n",
      "/kaggle/working/distributed_training_addon.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\r\n",
      "/kaggle/working/distributed_training_addon.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\r\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\r\n",
      "Resuming training from epoch 3\r\n",
      "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]\r\n",
      "Training Epoch 4/8:   0%|          | 0/172 [00:00<?, ?it/s]\r\n",
      "Validation Epoch 4/8:   0%|          | 0/43 [00:00<?, ?it/s]\r\n",
      "val loss:  225.7770076807708\r\n",
      "val acc:  0.5949870472208335\r\n",
      "val loss:  225.7770076807708\r\n",
      "val acc:  0.5949870472208335\r\n",
      "epoch_checkpoint_path:  /kaggle/working/checkpoint_dir/model_epoch_3.pth\r\n",
      "Training Epoch 5/8:   0%|          | 0/172 [00:00<?, ?it/s]\r\n",
      "Validation Epoch 5/8:   0%|          | 0/43 [00:00<?, ?it/s]\r\n",
      "val loss:  0.3809062436088261\r\n",
      "val acc:  0.8323864927509885\r\n",
      "val loss:  0.3809062436088261\r\n",
      "val acc:  0.8323864927509885\r\n",
      "epoch_checkpoint_path:  /kaggle/working/checkpoint_dir/model_epoch_4.pth\r\n",
      "Training Epoch 6/8:   0%|          | 0/172 [00:00<?, ?it/s]\r\n",
      "Validation Epoch 6/8:   0%|          | 0/43 [00:00<?, ?it/s]\r\n",
      "val loss:  1.4444454307367178\r\n",
      "val acc:  0.5107258101168023\r\n",
      "val loss:  1.4444454307367178\r\n",
      "val acc:  0.5107258101168023\r\n",
      "epoch_checkpoint_path:  /kaggle/working/checkpoint_dir/model_epoch_5.pth\r\n",
      "Training Epoch 7/8:   0%|          | 0/172 [00:00<?, ?it/s]\r\n",
      "Validation Epoch 7/8:   0%|          | 0/43 [00:00<?, ?it/s]\r\n",
      "val loss:  0.5429367053640413\r\n",
      "val acc:  0.7929373267281734\r\n",
      "val loss:  0.5429367053640413\r\n",
      "val acc:  0.7929373267281734\r\n",
      "epoch_checkpoint_path:  /kaggle/working/checkpoint_dir/model_epoch_6.pth\r\n",
      "Training Epoch 8/8:   0%|          | 0/172 [00:00<?, ?it/s]\r\n",
      "Validation Epoch 8/8:   0%|          | 0/43 [00:00<?, ?it/s]\r\n",
      "val loss:  0.6741687213107304\r\n",
      "val acc:  0.7156978593828114\r\n",
      "val loss:  0.6741687213107304\r\n",
      "val acc:  0.7156978593828114\r\n",
      "epoch_checkpoint_path:  /kaggle/working/checkpoint_dir/model_epoch_7.pth\r\n",
      "Training complete\r\n",
      "Model saved to /kaggle/working/cancer_detector_model.pth\r\n",
      "\r\n",
      "Example of model inference:\r\n",
      "Sample ID: ee702d31a1c95393038e3b7221398bfbb419c30d\r\n",
      "True label: 0 (Negative)\r\n",
      "Predicted class: 0 (Negative)\r\n",
      "Confidence: 0.9994\r\n"
     ]
    }
   ],
   "source": [
    "!python launch_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2264bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T08:32:17.060150Z",
     "iopub.status.busy": "2025-05-03T08:32:17.059458Z",
     "iopub.status.idle": "2025-05-03T08:32:17.063294Z",
     "shell.execute_reply": "2025-05-03T08:32:17.062694Z"
    },
    "papermill": {
     "duration": 0.011549,
     "end_time": "2025-05-03T08:32:17.064470",
     "exception": false,
     "start_time": "2025-05-03T08:32:17.052921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = run_distributed_training(\n",
    "#     embeddings_path='/kaggle/input/histopath-cancer-embeddings/embeddings',\n",
    "#     metadata_path='/kaggle/input/histopath-cancer-embeddings/metadata',\n",
    "#     batch_size=2048,  # Can use larger batch size now\n",
    "#     num_epochs=20\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61da37c",
   "metadata": {
    "papermill": {
     "duration": 0.005222,
     "end_time": "2025-05-03T08:32:17.075089",
     "exception": false,
     "start_time": "2025-05-03T08:32:17.069867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7296570,
     "sourceId": 11629781,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 325528,
     "modelInstanceId": 305936,
     "sourceId": 369424,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 325528,
     "modelInstanceId": 305085,
     "sourceId": 370130,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12100.31725,
   "end_time": "2025-05-03T08:32:20.511905",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T05:10:40.194655",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
